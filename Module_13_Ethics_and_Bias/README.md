# Ethics and Bias

## Topics covered in today's module
* Data Ethics
* Feedback loops
* Bias

## Main takeaways from doing today's assignment
- Ethics - well-founded standards of right and wrong that prescribe what humans ought to do
  - best-handled with a diverse team
  - Exampels of ethical considerations: opaque prcoesses and hidden bugs, feedback loops, bias in, bias out
  - Goal: build model that is enabling, inclusive, accountbable, robust, usefull and generalizable
- Bias - anything that causes a systematic difference between the true paramaeters of a population and the statistics used to estimate those params
    - Historical bias - society is biased
    - measurment bias - measured the wrong thing or wrong way
    - Aggregation Bias - models do not include all the necessary factors
    - Representation Bias - two stuations that are wrongly compared because of a perceived similarity
    - All datasets contain bias - which can spread and amplify much faster than a single biased human being or even groups of them
    - You must consider the interests and desires of the target popilation of a model and its stakeholders
        - What are some unintended conseqeunces?
  - Diversity holds teams accountable for bias, makes them more objectively evaluate facts and makes them more efficient
- Algorithims can learn from biased human decisions or from a dataset with an undersampled minority 
  

## Challenging, interesting, or exciting aspects of today's assignment
I loved the Survival of the Fittest tool since it was interactive and made me understand the ill-intended effeccts of a hiring algorihtim that was supposedly objective and made empathize with those deploying those models as AI ethics is hard to navigate. I also did not know that diversity had such a significant effect on innovation and was surprised that less than 12% of AI researchers are currently women. 

## Additional resources used 
Amazon hiring algorithim: https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G
